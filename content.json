{"pages":[],"posts":[{"title":"","text":"","link":"/2019/07/30/Typora-Hexo를 이용한 Blog관리 Tip/"},{"title":"Typora-Hexo","text":"Typora-Hexo를 이용하여 1시간 안에 Blog 글 올리기! 안녕하세요. 이제 Blog를 본격적으로 시작한지 일주일 밖에 안된 블룸베리입니다. 블로그를 시작하기로 마음먹고, 블로그에 글을 게제하기까지 우여곡절이 많았는데요, 이 글을 읽는 여러분께서는 조금이나마 시간을 아낄 수 있도록 글을 준비해보았습니다. (시간은 소중하니깐요..ㅎㅎ) 그럼 시작하겠습니다! (참고로 이 글은 https://www.stand-firm-peter.me/2018/01/06/Start/ 글을 바탕으로 제가 느낀점을 추가하여 작성한 글입니다!) 1. 블로그 url 정하기제일 먼저, 블로그를 시작하려면 블로그 주소(url)를 받을 블로그 프레임워크를 정해야 해요. 저는 아래 세 블로그 프레임워크를 두고 고민해보았습니다. Tistory Naver Blog Github 각자의 장단점이 있는데요, 저 같이 Tech Blog를 주로 작성하려고 하는 사람은 Github를 활성화해주면 향후 스펙용, 이직 준비용으로 좋아서 Github로 결정하게 됩니다. Github로 블로그 생성하기 궁금하신 분들은 위 링크를 참고해주세요. 이처럼 자신이 블로그 운영을 하는 목적에 따라 블로그 프레임워크를 정하시면 좋을 것 같습니다. 2. 정적 블로그 생성 툴 정하기WordPress와 같이 PHP를 자유자래로 사용하는 컴퓨터 공학도가 아닌 이상, 정적 생성기를 사용하는 것은 필수라고 본다. 정적 생성기로 무엇을 써도 무방하며, 본인이 사용하기 간편하고, contents를 효율적이고 깔끔하게 만들 수 있는 툴을 사용하면 된다. Jekyll : 시도해보았으나, ruby어로 구현된 문법에 친숙하지 못해 이내 포기함. Hexo : 학교 후배가 사용하여 알게됨. node.js를 사용하며, 시작이 간편하고, 기본으로 제공하는 템플릿 적용이 원활하여 이로 결정하게 됨. Gatsby : 웹 개발에 많이 사용하는 react를 사용한다고 함. (잘모름) 3. Markdown Editor 정하기Github 블로그는 모드 textfile의 일종인 markdown 형식을 사용하여 글을 게제한다. 따라서, 효율적인 Markdown Editor 사용이 블로그 글 게시 활동에 핵심이라 해도 과언이 아니다. 두 가지 editor 중에 hotkey가 직관적이라 사용하기 쉽고, Image Insert 혹은 Math module 첨부가 용이한 typora라는 editor를 최종 선택하였다. 3.1 Typora Image Insert 방법Typora에 drag-and-drop으로 Image Insert하기 위해서는 몇 가지 typora setting을 건드려야 한다. 상대 경로 활성화 하기 좌측 상단에 ‘File-Preference-Images Insert 항목에서 ‘Use relative path if possible‘ 체크 박스를 활성화 한다. Copy Image file to folder 활성화 하기 이게 뭐하는거냐? Github에 사진을 업로드 하기 위해서는 반드시 서버 상에도 그 이미지를 업로드 해야 한다. 다시 말해, 단순히 typora editor에 drag-and-drop한다고 해서 markdown 파일에 그림이 첨부되는게 아니다. 좀 복작하지만, 비슷한 효과(?)를 내기 위해 drag-and-drop했을 경우 설정된 경로로 drop한 이미지가 복사되는 기능을 활성화 한 것이라 볼 수 있다. 방법은 아래와 같다. ‘Edit - Image Tools - When Inesrt Local Image - Copy Image File to Folder’ 체크 ​ 저장 경로 설정하기 제일 중요한 부분이다! 이것 때문에 주말에 5시간동안 삽질을 했다.. 부디 그런일 마시길. 저장 경로를 이해하기 위해서 먼저 Hexo의 _config.yml파일을 살펴봐야 한다. Github서버에 Markdown파일을 업로드하면 _config.yml파일에 permalink에서 지정한 형식으로 경로가 설정된다. 예를 들어 ‘Mobilenetv3.md’파일을 ‘나의 directory/source/Mobilenetv3.md ‘라는 곳에 생성했다고 하자. 실제로 deploy를 하게되면 github Web 주소 상에서는 https://BloomBerry.github.io/2019/07/28/Mobilenetv3 라는 주소로 index.html파일이 생성된다. 이때 중요한 것은 동일한 경로, 예컨데 ‘나의 directory/source’에 Mobilenetv3라는 디렉토리를 만들고 그곳에 이미지를 넣는다고 생각하면 오산이다. Hexo는 themes 디렉토리 내부 경로만 참조하기 때문에 ‘themes/자신의 themes’ 경로에 이미지를 추가해줘야 한다. 예컨데 icarus를 사용한다면 ‘themes/icaurs/source/MobilenetV3’ 경로에 image를 추가해야 한다. 이를 원활하게 하기 위해 typora-root-url과 typora-copy-images-to를 이용하면 drag-and-drop하여 Image를 추가할 수 있다. 주의할 점은 github에 deploy하기 전에 반드시 두 줄을 #으로 주석처리해야 한다. [Optional] 글 별로 이미지를 관리하고 싶을 때 개인의 취향에 맞기겠지만, markdown별로 첨부한 이미지를 관리하고 싶을 때는 _config.yml에 post_asset_folder를 True로 만들어 주면 된다. command 창에 hexo new New_Title.md라고 치면 typora-copy-images-to에서 설정한 경로에 md파일명과 동일한 디렉토리가 생성되는 것을 볼 수 있다. 짜잔! 이 글역시 위 방법으로 만든 글이다. 이 글을 작성하는데 1시간 정도밖에 걸리지 않았다. 놀랍군!!","link":"/2019/07/30/Typora-Hexo/"},{"title":"Mobilenetv3","text":"Searching for Mobilenet V32019.05.09 Andrew Howard, et. al. from Google AI AbstractMobilenet V3는 hardware-aware NAS (Neural Architecture Search)기법인 NetAdapt을 사용하여 타겟하는 Mobile Device CPU에서 Latency를 줄임과 동시에 성능을 끌어올릴 수 있음을 보였다는데 의의가 있다. 본 논문에서는 Mobilenet V3를 Mobilenet V3-Large와 MobilenetV3-Small 두 가지 버전으로 나누어 Classification, Object Detection과 Semantic Segmentation을 수행하였다. Segmantic Segmentation의 경우는 LR-SPP (Lite Reduced-Spatial Pyramid Pooling)라는 새로운 Decoder구조를 제안하였다. 실험 결과 MobilenetV3-Lage의 Classification은 MobilenetV2에 비해 ImageNet에서 Top-1 accuracy가 3.2% 향상됨과 동시에 Latency가 15% 감소하였다.(MobilenetV3-Small은 accuracy 4.6% 감소) 1. Introduction이 논문은 모바일 디바이스 상에서 속도-성능간 trade-off를 최적화하기 위한 방안들을 다룬다. Complementary Search Engine : Latency &amp; Accuracy를 목표값으로 NAS (Neural Architecture Search)를 진행함. 모바일 셋팅에 최적화된 형태의 비선형 함수 H-swish 함수 사용 새로운 network 구조 제안 : Inverted Resudial + Squeeze-and-Excite 새로운 Segmentation Decoder (LR-SPP) 2. Related WorkAccuracy-Latency 최적화를 위한 다양한 연구 결과를 요약하면 다음과 같다. SqueezeNet : 1x1 conv로 parameter 수를 줄임 Mobilenet V1 : Depthwise Separable conv로 channel-wise 곱셈 paremeter 를 줄임 Mobilenet V2 : Inverted Residual과 Linear Bottleneck을 사용하여 모바일 디바이스 상에서 효율적인 구조 채택 ShuffleNet : Group conv + Channel shuffle을 사용하여 MAC 를 줄임 CondenseNet : Group Conv에 사용될 connections를 학습함 ShiftNet : Shift operation을 point-wise conv와 사용하여 계산량이 많은 Spatial conv 대체 3. Efficient Mobile Building BlocksMnasNet은 Mobilenet V2의 bottleneck 기본 뼈대에서 squeeze-and-excite구조와 light attention module을 추가한 구조를 채택하고 있다. Mobilenet V3는 MnasNet구조에서 swish non-linearity로 업데이트하였으며, fixed-point arithmetic구조에서 비효율적인 sigmoid를 hard sigmoid 구조를 채택하였다. 4. Network SearchNetwork Search는 network의 최적 Block를 찾는데 Platform-aware NAS와 Layer 수 최적화를 위한 NetAdapt 알고리즘을 사용한다. 4.1 Platform-Aware NAS for Block-wise SearchPlatform-Aware NAS는 [43] MnasNet: Platform-Aware Nerual Architecture Search for Mobile 에서 다루고 있는 다중목적 보상함수를 사용하고 있다.$$ACC[m]×[LAT[m]/TAR]^w$$위 식은 Parto-optimal solution을 최적화하기 위해 Target Latency [TAR]항을 분모로 모델 m에 대하여 Accuracy [ACC[m]]와 Latency[LAT[m]] 항을 사용한다. *w은 ACC와 *LAT 간의 비율을 조정하는 항이다. 기존 논문 [43]에서는 w=-0.07를 사용하였지만, 본 논문에서는 작은 모델에 최적화하도록 LAT\\에 weight를 더 주기 위해 w=-0.15를 주어 모델 m을 찾는다. 4.2 NetAdapt for Layer-wise SearchNetAdapt는 *[46] Netadapt: Platform-Aware neural network adaptation for mobile applications*에서 다루고 있다. 요약하면, 4.1절에서 다중목적 보상 NAS로 찾은 seed architecture로 시작한다. 각 step에 대해서 새로운 proposal을 제안한다. 이때, proposal은 이전 step에서의 model에 비해 latency가 최소한계치 δ 만큼 감소시켜야 한다. δ=0.01L L= seed model의 Latency Pretrained weight 값으로 이전 step에서 사용한 model 중 truncated된 부분을 제외한 부분을 채택하며, 새로 생성된 layer는 randomly initialized시킨다. Proposal한 model들을 T step만큼 fine tuning을 거치고 accuracy를 생성한다. T=10,000를 사용 Evaluation Metric을 통해 proposal된 model들 중 최고의 proposal model을 찾는다. Eval Metric =max $$Δ|ACC|\\overΔLAT$$ Insight: Proposal이 discrete하기 때문에 trade-off curve slope를 최대화 함 Proposal 시 변경 가능한 요소들 Expansion Layer 크기 Bottleneck 크기 Target Latency에 도달할 때까지 1~2 과정을 반복한다. 5. Network ImprovementsNetwork Search로 찾은 모델을 더 개선하기 위해 계산량이 많은 Layer를 변경하고, Quantization frinedly한 H-swish 비선형 함수를 제안한다. 5.1 Redesigning Expensive LayersN기존 Network Search로 찾은 모델은 시작, 끝 Layer에서 유독 많은 계산량을 보였다. 이는 기존 Network Search Method의 search space를 벗어나는 부분으로, 수동 tuning을 하여 Accuracy는 불변하고, Latency를 줄여주었다. Final Layer 7×7 Conv Layer into Average pooling Layer Same Accuracy 10 ms Latency (15% of running time) &amp; 30MAdds drop Initial Layer channel 32 channel into 16 channel Non-linearity Function : swish or ReLU Same Accuracy 3 ms Latency &amp; 10MAdds drop 5.2 Nonlinearitiesswish는 *[36] Searching for Activation Function*에서 제안한 비선형 함수로 ReLU를 대체하여 neural network의 accuracy를 향상시킨다. 이때, sigmoid σ(x)를 사용하기에 계산량의 증가가 있다.$$swish(x)=x⋅σ(x)$$sigmoid 함수 σ(x)의 계산량을 모바일 디바이스 상에서 줄이기 위한 두 가지 방법을 제안한다. h-swish $$h−swish[x]=x\\frac{ReLU6(x+3)}6$$ ReLU6는 어떤 Hardware / Software platform에서도 최적화가 가능하다. Framework마다 Sigmoid 구현하는데 따른 numerical precision loss를 없앨 수 있다. Quantized Sigmoid조차도 ReLU보다 느리다. 위 세 가지 이유로, sigmoid 함수를 ReLU6로 바꾼다. h-swish 후 배치 비선형 함수로 인한 Latency는 뒤로 갈 수록 feature-map의 크기가 줄어듦에 따라 감소한다. 따라서, h-swish를 network의 뒤에만 배치하는 것이 더 효과적임을 실험적으로 구했다. 위에 언급한 최적화를 사용함에도 불구하고, h-swish는 여전히 latency가 존재한다. 그럼에도 accuracy-latency tradeoff가 긍정적이고, 향후 software optimize에 따른 성능 향상을 염두하여 Network의 뒷부분에 H-swish 비선형 함수를 사용한다. ReLU와 같은 linear 함수 사용 시, latency bottleneck은 메모리 접근 시 발생함. 효과적으로 메모리 배치 시 최적화 가능함. 5.2.1. Large Squeeze-and-Excite MnasNet 논문에서는 Squeeze-and-excite의 channel은 convolution layer의 채널 수에 상대적이었다. 하지만, 본 논문에서는 Expansion Layer의 1/4 사이즈로 고정시켰다. 이로 인한 accuracy는 향상한 반면, parameter는 소폭만 증가헀다. 5.3 Mobilenet V3 DefinitionMobilenet V3 - Large 구조는 아래와 같다. (Mobilenet-Small은 위 Table 2 참고)* 6. Experiments 비교 대상: Accuracy vs. Latecny &amp; MAdds (Multiply adds) Training setup 학습 환경 : 4x4 TPU Pod Optimizer : RMSPropOptimizer with 0.9 Momentum (Tensorflow) Batch size: 4,096 (128 images per chip) Learning Rate 스케줄 : 0.01 initial rate of decaying 0.01 every 3 step dropout : 0.8 l2 weight decay 1e-5 Exponential moving Average with 0.9999 decay Batch Norm : average decay of 0.99 Latency Measurement Hardware: Google Pixel phones Framework: Tensorflow Lite Benchmark Tool Core 갯수: Single 6.1 Classification Dataset: ImageNet 6.2 Result Mobilenet V3-Large 1.0 성능(Accuracy) &gt; SOTA Mobile Device Target 모델 Mobilenet V3-Small 0.75 지연시간(Latency) &lt; SOTA Mobile Device Target 모델 이미지 해상도(Resolution)이 큰 Mobilenet-V3-Small이 Mobilenet-V3-Large보다 미세하게 성능이 우수함. 하지만, 이미지 해상도는 보통 결정된 값이기에 큰 의미는 없는듯 6.2.1 Ablation Study 전체 Network를 H-swish로 대체하면 성능-속도 trade-off가 좋지 않음 성능 증가 (0.9%) 속도 감소 (-32%) Network 뒷부분만 교체하면 성능-속도 trade-off가 조아짐 성능 증가(0.7%) 속도 감소 (-12%) 크게 의미 없는 수치같음… 6.2 Detection Datset: MsCOCO OD Architecture : SSD Lite (OS 16 ~ OS256) OS 16 (C4) MobilenetV3-Lage 13th bottleneck block MobileentV3-Small 9th bottleneck block OS 32 (C5) After pooling layer (Small &amp; Large) Reduced Channel into Half ImageNet의 클래스 수 (1,000)에 비해 MsCOCO의 클래스 수 (80)이 작기에 기존 channel 수는 redundunt하다고 여김 실제로 성능하락 없이 속도 향상(15%)만 가져옴 Mobilent V2와 동일한 성능 (22.0 mAP vs. 22.1 mAP)이면서 빠른 속도 (150 ms vs. 200 ms) 25% 속도 향상 보임 6.4 Semantic Segmentation Dataset : CityScapes Fine Images (mIOU) Pretraiend Model 사용 x Channel 절반 사용 (OD와 동일한 이유) CityScapes 클래스 19 &lt;&lt; ImageNet 클래스 1,000 LR-ASPP (Lite Reduced design of Atrous Spatial Pyramid Pooling module) 1x1 conv + Global Average Pooling Layer (+ Squeeze-and-Excite) Pooling Layer에 더 큰 stride, kernerl을 사용함 마지막 Layer에 Atrous conv.와 skip connection을 사용함. Mobilenet V3-Large: ESPNet v2, CCC2, ESPNetv1보다 각각 10.5%, 10.6%, 12.3% 성능 향상 + 무게 감소 (Madds) Mobilenet V3-Small: ESPNet v2, CCC2, ESPNetv1보다 각각 1.7, 1.59, 2.24 배 속도 향상 + 6.2% 성능 향상 7. Conclusion Classificaiton, Object Detection, Semantic Segmentation 모두 좋은 결과를 보임 Mobile model의 차세대 Network 제시 비선형 함수 h-swish 사용 양자화에 친화적인 Squeeze-and-Excite 사용 LR-ASPP 선보임.","link":"/2019/07/28/Mobilenetv3/"},{"title":"","text":"결혼을 배우다지난 주말에 대학 동문 동기, 후배들과 모여 ‘결혼’을 키워드로 각자 생각을 나누는 한 주를 보내게 되었다. 그러면서 내 방 서랖에 꼿혀서 방치되어 있던 ‘결혼을 배우다’를 읽으며 느낀 점을 간단히 정리해보았다. &lt;관찰&gt;1. 두려워하던 사랑에 빠지다 나의 하나님. 나에게 주어졌던 사명감 무게들이 가족에게 전해질까봐 저자는 결혼이 두려웠다고 한다. 그러나 문득 자신이 하나님을 너무나 과소평가 하고 있음을 느낀다. …” 네가 결혼했을 때 나는 네 개인의 아버지에세 네 가정의 아버지가 된단다.” 사랑은 기다림이다. 빠른 사과보다는 묵묵히 기다리며 그 인내의 시간을 기도로 채우는 시간이 필요하다. 저자는 결혼 준비기간에 신혼 가구를 사는 중에 신부가 고른 가구들이 자신의 취향이 아니지만 당신이 좋아해서 샀다는 말을 할지 말지 고민했었다. 말을 하지 않으면 평생 자신이 이런 종류의 가구를 좋아할 것이란 오해를 신부가 했을 것이고, 말을 하면 신부의 마음이, 자존심이 상할 줄 알았기 때문이다. 결국 한참 망설이다 주님이 주신 마음에 순종하여 말을 헀고, 마음이 상한 신부에게 빠르게 사과하려다가 사랑의 속성, ‘기다림’의 시간을 갖는다. 기다리는 고통의 시간을 전전긍긍하기보다 기도로 채우면 하나님이 거두실 것이다. 2. 처음부터 남편이고 아내였던 사람은 없다 인생에 ‘낭비’를 받아들일 것인가. 정말 공감이 가는 대목이다. 솔로일 때는 겪어 보지 못할, 양육 문제, 아내와의 문제가 발생하면 이를 받아들이고 자신의 커리어보다 중요시 할 수 있곘는가? 흔히 남자는 가정을 책임지는 일에, 여자는 남편과 자녀에 대한 일에 약점을 가지고 있다고 한다. … “아담에게 이르시되… 땅은 너로 말미암아 저주를 받고 너는 네 평생에 수고하여야 그 소산을 먹으리라…”창3:17-19 “여자에게 이르시되 내가 네게 임신하는 고통을 크게 더하리니 네가 수고하고 자식을 낳을 것이며 너는 남편을 원하고 남편을 너를 다스릴 것이니라.” 창 3:16 성경 말씀에 순종하는 것이야 말로 참 지혜이다. 성경에는 뭐라 써 있는가? “아내를 맞은 새신랑을 군대에 내보내서는 안 되고, 어떤 의무도 그에게 지우어서는 안됩니다. 그는 한 해동안 자유롭게 집에 있으면서, 결혼한 아내를 기쁘게 해주어야 합니다.” 신 24:5, 새번역 설령 일에 있어 작업의 흐름을 놓치거나, 회사원으로서 감각과 의지마저 놓아버린다 하더라도 아내를 기쁘게 하는 것이 주님의 말씀이다. 실제로, 저자는 이 말씀에 순종하여, 1년간 작가로서 감각과 의지를 놓았지만, 하나님이 아내의 마음에 쉽게 흔들리지 않는 신뢰를 심어 주셔서 더 긴 시간을 같은 마음으로 걸어갈 수 있게 되었다. 뿐만 아니라, 그 1년의 시간동안 함께 풍성하게 먹고, 마시면서 성경에서 말하는 낙을 누린 그 시기를 작가는 ‘거룩한 낭비‘ 라는 표현을 쓴다. 신앙의 색채를 맞춰갈 줄 알아야 한다. “홀로였을 때의 신앙과 신앙과 선교에 대한 가치관도 가정을 이루면서 조정해 가야한다. …(중략)… 서로의 신앙적 색채까지 함께 점검하고 동의하고 교류해야 한다. 자신의 신앙의 색채와 완벽하게 100% 일치하는 사람은 이 세상에 없다. 다만, 자신과 신앙의 색체를 맞춰 갈 수 있는 사람을 만나야 겠다. 결혼은 순종이다. 남편은 아내가 사랑스러운 모습이 없더라도 사랑해야 하고, 아내는 남편이 존경할만한 모습이 없어도 복종하고 존중하는 것, 이것이 순종이다 요새도 이혼이 잦지만, 예수님 당시 헬렌 학파는 아내가 빵을 태우기만 해도 이혼 사유가 되었다. 또, 성적으로 문란했던 로마 시대는 결혼이 동거 이상의 의미가 없었다고 한다. 이때 예수님께 바리새인들은 “무엇이든지 이유만 있으면 남편이 아내를 버려도 됩니까?” 라고 묻는다. 철저히 자신을 위해, 내게 맞지 않으면 헤어지는 문화가 지금과 매우 흡사하다. 그러나 저자는 결혼은 하나님이 나를 위해 아내를 예비하신 것이 아니라, 아내를 위해 내가 있는 것이라고 말했다. 즉, 결혼 전에는 아내를 여자친구로서 사랑했다면, 결혼 이후는 언약에 대한 이행으로 (순종으로) 사랑해야 한다. “그런즉 이제 둘이 아니요 한 몸이니 그러므로 하나님이 짝지어 주신 것을 사람이 나누지 못할지니라 하시니” 마 19:6 3. 나는 오늘도 너로 인해 좋다. 사과를 미루지 마라 저자는 결혼한 후에 끊임없이 상대방을 용서하고 자신의 잘못을 살펴야 한다고 한다. 왜냐하면 사탄은 어떤 빌미를 통해서라도 끊임없이 한 몸인 부부를 쪼개려 하기 때문이다. 우리는 연약한 사람이기에 분을 내는 것은 어쩔 수 없는 것이지만, 해가 지도록 분을 품지 않는 부분은 순종에 대한 영역이다. 서로를 ‘이해’한다는 생각 때문에 저자는 해야 할 말, 사과의 말을 미루지 말라고 한다. 지혜 중에 지혜가 아닐 수 없다. 솔로일 때 시간 보내는 법 혼자일 때 감사하지 않고, 행복하지 않은 인생은 배우자를 만나도 크게 달라지지 않는다. 주님과 지속적인 만남의 시간은 때문에 필수적이라고 할 수 있다. 배우자를 볼 때 외모, 장래성을 봐야 하나? 물론 외모는 중요하다. 청년 시절 주님이 주신 외모를 가꾸지 않는 것은 잘못된 것이다. 그러나 외모지상주의가 만연한 세상에서 외모만 보는 것은 바람직하지 않다. 결혼 전보다 결혼 후에 더 아름다워 보일 수 있다. 그것은 은혜다. 또, 장래성도 있으면 좋겠지만, 주님께 순종할 줄 아는 사람이라면 그것만으로도 장래성이 충분하다. &lt;묵상&gt;나는 어떠한가? 나한테 적용해보자. 우선 내가 결혼하기 전에 가다듬어져야 할 부분들이 책을 읽으면서 와닿았다. 그것은 말씀에 ‘순종’하는 부분과 ‘기도’로 주님과 친밀한 교제를 이어가야 하는 부분이다. 쉬운 선택을 걱정하던 저자의 걱정대로, 나는 쉬운 선택을 하면서 안정적인 삶을 누리고 있지만, 주님이 살아계시지 않는 삶을 살아가고 있는 것 같다. 주님이 없이도, 먹고 살 수 있기 때문이다. 주님께 순종하는 훈련을 말로만 하지 않으려면 끊임없이 가슴뛰는 도전을 해야겠구나. 특별히, 이직에 대한 생각이 드는 요즈음, 불안하고 한 번도 가보지 않은 길로 고민을 하는 이떄에 이 책을 통해 주님께 기도하며 그 과정을 인내해야겠다. 그럼으로써 ‘오래 참는’ 사랑의 일부를 훈련할 수 있겟다. 또, 결혼 상대, 배우자에 대한 나의 잘못된 개념이 제대로 잡혔다. 성경은 배우자를 ‘돕는 베필’이라고 말씀하고 있다. 내가 배우자될 분을 위해 존재하는 것이다. 이를 실현하기 위해서라도 내가 살고 있는 위치에서 섬김 훈련을 하는 것이 성공적인 결혼 생활을 하는 것의 준비과정이라는 생각을 했다. 이를 위해 교회에서 하는 ‘리더십 훈련’을 자원해서 다음 텀에는 키멤버 훈련을 참가해야겠다. 외모, 스펙, 학벌 등 세상적인 시야로 배우자를 바라보지 않고 주님이 인도해주신 배우자를 분별하기 위해 꺠어 있을 수 있도록 미디어에 노출되는 시간도 조절을 해야 겠다. 무분별하게 유투브를 보며 time killing하는 시간을 하루 1시간 이내로 제한하고, 그 외 여유 시간은 기도와 말씀 묵상 등 베이직 훈련을 하는 시간으로 채워야 겠다. 이를 위해 weekly를 매주 써야겠다. &lt;적용&gt; 이직에 대한 약속의 말씀을 정해서 하루 한 번 자기 전에 10분씩 기도하고 자기 다음 텀 교회 리더십 자원서 작성하기 Weekly를 매주 주일 자정 전까지 작성하기","link":"/2019/08/11/결혼을 배우다/"}],"tags":[{"name":"Static Generator, Hexo, Typora, Blog","slug":"Static-Generator-Hexo-Typora-Blog","link":"/tags/Static-Generator-Hexo-Typora-Blog/"},{"name":"Mobilent v3, AI, Object Detection, Quantization, Tensorflow Lite","slug":"Mobilent-v3-AI-Object-Detection-Quantization-Tensorflow-Lite","link":"/tags/Mobilent-v3-AI-Object-Detection-Quantization-Tensorflow-Lite/"}],"categories":[]}